# Google Document AI to Bitwarden Export

This application streamlines the process of exporting structured data from Google Document AI and formatting it for import into Bitwarden as an identity item.

## Overview

The primary function of this tool is to automate the transfer of personal identification data from a document processed by Google Document AI to a Bitwarden vault. It achieves this by:

1.  Processing a document (e.g., a driver's license or Medicare card) using a specialized Google Document AI processor.
2.  Exporting the extracted entities (such as name, date of birth, license number) into a structured `export.json` file.
3.  Mapping the data from `export.json` to the fields in the `bitwarden_id_template.json` file.
4.  Generating a populated JSON file that can be imported into Bitwarden.

## Files

-   `bitwarden_id_template.json`: A template file representing a Bitwarden identity item. This file contains the structure and fields that Bitwarden expects for an identity, with empty values that will be populated by the application.
-   `export.json`: This file is the output from the Google Document AI processor. It contains the key-value pairs of the data extracted from the source document. This file is generated by the application and is then used as the input for populating the Bitwarden template.

## Workflow

1.  **Data Extraction**: The application sends a document to the Google Document AI API for processing. The API extracts relevant information based on the trained model.
2.  **Generate `export.json`**: The extracted data is then saved locally as `export.json`.
3.  **Populate Template**: The application reads the `export.json` file and the `bitwarden_id_template.json` file. It then maps the values from the export file to the corresponding fields in the template.
4.  **Bitwarden Import File**: The populated template is saved as a new JSON file (e.g., `import_bitwarden.json`), which is ready to be imported into your Bitwarden vault.

## Usage

1.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

2.  **Run the application:**
    To process a document, you will need to provide your Google Cloud project details and the path to the document.

    ```bash
    python main.py \
        --file-path /path/to/your/document.pdf \
        --project-id your-gcp-project-id \
        --location your-gcp-location \
        --processor-id your-processor-id \
        --credentials /path/to/your/credentials.json
    ```

    -   `--file-path`: The path to the input document file.
    -   `--project-id`: Your Google Cloud project ID.
    -   `--location`: The Google Cloud location for the Document AI processor (e.g., 'us').
    -   `--processor-id`: Your Document AI processor ID.
    -   `--credentials`: The path to your Google Cloud service account credentials JSON file.

    If you do not provide the command-line arguments, the script will use mock data to generate the `export.json` and `import_bitwarden.json` files. This is useful for testing the data mapping functionality without needing to connect to the Google Cloud API.

(Note: This `README.md` provides a high-level overview. The actual implementation details would be found in the application's source code.)
